1. Several variants of the Long Short-Term Memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995.
2. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. 
3. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment. 
